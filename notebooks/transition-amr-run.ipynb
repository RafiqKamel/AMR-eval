{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from cache /Users/rafiqmazen/.cache/torch/DATA/AMR3.0/models/amr3.0-structured-bart-large-neur-al/seed42/checkpoint_wiki.smatch_top5-avg.pt\n",
      "| [en] dictionary: 46088 types\n",
      "| [actions_nopos] dictionary: 16544 types\n",
      "----------loading pretrained bart.large model ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/rafiqmazen/.cache/torch/hub/pytorch_fairseq_main\n",
      "2023-11-17 15:07:03 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz from cache at /Users/rafiqmazen/.cache/torch/pytorch_fairseq/40858f8de84f479771b2807266d806749e9ad0f8cb547921c35a76ae9c3ed0f6.099ef973524a5edb31b1211569b67bcc2863bc6d00781b79bac752acf8e48991\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransition_amr_parser\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AMRParser\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Download and save a model named AMR3.0 to cache\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mAMRParser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAMR3-structbart-L\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tokens, positions \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mtokenize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe girl travels and visits places\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Use parse_sentence() for single sentences or parse_sentences() for a batch\u001b[39;00m\n",
      "File \u001b[0;32m~/GR/transition-amr-parser/src/transition_amr_parser/parse.py:733\u001b[0m, in \u001b[0;36mAMRParser.from_pretrained\u001b[0;34m(cls, model_name, dict_dir, roberta_cache_path, fp16, inspector, beam, nbest, num_samples, sampling_topp, temperature)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mload from cache \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 733\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_checkpoint(checkpoint_path, dict_dir,\n\u001b[1;32m    734\u001b[0m                            roberta_cache_path, fp16, inspector,\n\u001b[1;32m    735\u001b[0m                            beam, nbest, num_samples, sampling_topp,\n\u001b[1;32m    736\u001b[0m                            temperature)\n",
      "File \u001b[0;32m~/GR/transition-amr-parser/src/transition_amr_parser/parse.py:784\u001b[0m, in \u001b[0;36mAMRParser.from_checkpoint\u001b[0;34m(cls, checkpoint, dict_dir, roberta_cache_path, fp16, inspector, beam, nbest, num_samples, sampling_topp, temperature)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# otherwise, the default dict folder is read from the model args\u001b[39;00m\n\u001b[1;32m    783\u001b[0m use_cuda \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mcpu\n\u001b[0;32m--> 784\u001b[0m models, model_args, task \u001b[39m=\u001b[39m load_models_and_task(\n\u001b[1;32m    785\u001b[0m     args, use_cuda, task\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m )\n\u001b[1;32m    787\u001b[0m \u001b[39m# overload some arguments\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[39m# SequenceGenerator args: sampling_topk sampling_topp temperature\u001b[39;00m\n\u001b[1;32m    789\u001b[0m args\u001b[39m.\u001b[39mbeam \u001b[39m=\u001b[39m beam\n",
      "File \u001b[0;32m~/GR/transition-amr-parser/src/transition_amr_parser/parse.py:279\u001b[0m, in \u001b[0;36mload_models_and_task\u001b[0;34m(args, use_cuda, task)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fairseq load from task method\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    _type_: _description_\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39m# if `task` is not provided, it will be from the saved model args\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m models, model_args, task \u001b[39m=\u001b[39m checkpoint_utils\u001b[39m.\u001b[39;49mload_model_ensemble_and_task(\n\u001b[1;32m    280\u001b[0m     args\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m:\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m    281\u001b[0m     arg_overrides\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mmodel_overrides,\n\u001b[1;32m    282\u001b[0m     task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39m# Optimize ensemble for generation\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/fairseq/checkpoint_utils.py:283\u001b[0m, in \u001b[0;36mload_model_ensemble_and_task\u001b[0;34m(filenames, arg_overrides, task, strict, suffix, num_shards)\u001b[0m\n\u001b[1;32m    281\u001b[0m args \u001b[39m=\u001b[39m state[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m task \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     task \u001b[39m=\u001b[39m tasks\u001b[39m.\u001b[39;49msetup_task(args)\n\u001b[1;32m    285\u001b[0m \u001b[39m# build model for ensemble\u001b[39;00m\n\u001b[1;32m    286\u001b[0m model \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mbuild_model(args)\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/fairseq/tasks/__init__.py:28\u001b[0m, in \u001b[0;36msetup_task\u001b[0;34m(task_cfg, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(task_cfg, DictConfig):\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m TASK_REGISTRY[task_cfg\u001b[39m.\u001b[39m_name]\u001b[39m.\u001b[39msetup_task(task_cfg, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m TASK_REGISTRY[task_cfg\u001b[39m.\u001b[39;49mtask]\u001b[39m.\u001b[39;49msetup_task(task_cfg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/GR/transition-amr-parser/src/fairseq_ext/tasks/amr_action_pointer_bart.py:280\u001b[0m, in \u001b[0;36mAMRActionPointerBARTParsingTask.setup_task\u001b[0;34m(cls, args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mbart_large\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m args\u001b[39m.\u001b[39march:\n\u001b[1;32m    279\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mloading pretrained bart.large model \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m     bart \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mhub\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mpytorch/fairseq\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbart.large\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    281\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39minitialize_with_watbart\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m args\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mkeys() \u001b[39mand\u001b[39;00m args\u001b[39m.\u001b[39minitialize_with_watbart \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/torch/hub.py:542\u001b[0m, in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgithub\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    539\u001b[0m     repo_or_dir \u001b[39m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, \u001b[39m\"\u001b[39m\u001b[39mload\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    540\u001b[0m                                        verbose\u001b[39m=\u001b[39mverbose, skip_validation\u001b[39m=\u001b[39mskip_validation)\n\u001b[0;32m--> 542\u001b[0m model \u001b[39m=\u001b[39m _load_local(repo_or_dir, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    543\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/torch/hub.py:572\u001b[0m, in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m hub_module \u001b[39m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[1;32m    571\u001b[0m entry \u001b[39m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[0;32m--> 572\u001b[0m model \u001b[39m=\u001b[39m entry(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    574\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mremove(hubconf_dir)\n\u001b[1;32m    576\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/fairseq/models/bart/model.py:115\u001b[0m, in \u001b[0;36mBARTModel.from_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, bpe, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\n\u001b[1;32m    106\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    112\u001b[0m ):\n\u001b[1;32m    113\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mfairseq\u001b[39;00m \u001b[39mimport\u001b[39;00m hub_utils\n\u001b[0;32m--> 115\u001b[0m     x \u001b[39m=\u001b[39m hub_utils\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    116\u001b[0m         model_name_or_path,\n\u001b[1;32m    117\u001b[0m         checkpoint_file,\n\u001b[1;32m    118\u001b[0m         data_name_or_path,\n\u001b[1;32m    119\u001b[0m         archive_map\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mhub_models(),\n\u001b[1;32m    120\u001b[0m         bpe\u001b[39m=\u001b[39;49mbpe,\n\u001b[1;32m    121\u001b[0m         load_checkpoint_heads\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    122\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m BARTHubInterface(x[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m], x[\u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m], x[\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/fairseq/hub_utils.py:70\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name_or_path, checkpoint_file, data_name_or_path, archive_map, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muser_dir\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m     68\u001b[0m     utils\u001b[39m.\u001b[39mimport_user_module(argparse\u001b[39m.\u001b[39mNamespace(user_dir\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39muser_dir\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m---> 70\u001b[0m models, args, task \u001b[39m=\u001b[39m checkpoint_utils\u001b[39m.\u001b[39;49mload_model_ensemble_and_task(\n\u001b[1;32m     71\u001b[0m     [os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(model_path, cpt) \u001b[39mfor\u001b[39;49;00m cpt \u001b[39min\u001b[39;49;00m checkpoint_file\u001b[39m.\u001b[39;49msplit(os\u001b[39m.\u001b[39;49mpathsep)],\n\u001b[1;32m     72\u001b[0m     arg_overrides\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     76\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m: args,\n\u001b[1;32m     77\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m: task,\n\u001b[1;32m     78\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m: models,\n\u001b[1;32m     79\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/fairseq/checkpoint_utils.py:279\u001b[0m, in \u001b[0;36mload_model_ensemble_and_task\u001b[0;34m(filenames, arg_overrides, task, strict, suffix, num_shards)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m PathManager\u001b[39m.\u001b[39mexists(filename):\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mModel file not found: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(filename))\n\u001b[0;32m--> 279\u001b[0m state \u001b[39m=\u001b[39m load_checkpoint_to_cpu(filename, arg_overrides)\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m shard_idx \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    281\u001b[0m     args \u001b[39m=\u001b[39m state[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/fairseq/checkpoint_utils.py:224\u001b[0m, in \u001b[0;36mload_checkpoint_to_cpu\u001b[0;34m(path, arg_overrides)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Loads a checkpoint to CPU (with upgrading for backward compatibility).\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(PathManager\u001b[39m.\u001b[39mget_local_path(path), \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 224\u001b[0m     state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\n\u001b[1;32m    225\u001b[0m         f, map_location\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m s, l: default_restore_location(s, \u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m args \u001b[39m=\u001b[39m state[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m arg_overrides \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/torch/serialization.py:795\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/spring2/lib/python3.9/site-packages/torch/serialization.py:1020\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[39massert\u001b[39;00m key \u001b[39min\u001b[39;00m deserialized_objects\n\u001b[1;32m   1019\u001b[0m typed_storage \u001b[39m=\u001b[39m deserialized_objects[key]\n\u001b[0;32m-> 1020\u001b[0m typed_storage\u001b[39m.\u001b[39;49m_storage\u001b[39m.\u001b[39;49m_set_from_file(\n\u001b[1;32m   1021\u001b[0m     f, offset, f_should_read_directly,\n\u001b[1;32m   1022\u001b[0m     torch\u001b[39m.\u001b[39;49m_utils\u001b[39m.\u001b[39;49m_element_size(typed_storage\u001b[39m.\u001b[39;49mdtype))\n\u001b[1;32m   1023\u001b[0m \u001b[39mif\u001b[39;00m offset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1024\u001b[0m     offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transition_amr_parser.parse import AMRParser\n",
    "\n",
    "# Download and save a model named AMR3.0 to cache\n",
    "parser = AMRParser.from_pretrained('AMR3-structbart-L')\n",
    "tokens, positions = parser.tokenize('The girl travels and visits places')\n",
    "\n",
    "# Use parse_sentence() for single sentences or parse_sentences() for a batch\n",
    "annotations, machines = parser.parse_sentence(tokens)\n",
    "\n",
    "# Print Penman notation\n",
    "print(\"annotations\", annotations)\n",
    "\n",
    "# Print Penman notation without JAMR, with ISI\n",
    "amr = machines.get_amr()\n",
    "print(\"penman\",amr.to_penman(jamr=False, isi=True))\n",
    "\n",
    "# Plot the graph (requires matplotlib)\n",
    "amr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class AbstractParser(ABC):\n",
    "    @abstractmethod\n",
    "    def tokenize(self, text):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def encode(self, text):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def decode(self, tokens):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:01:55 | INFO | transformers.tokenization_utils | Model name 'facebook/bart-large-cnn' not found in model shortcut name list (bart-large, bart-large-mnli, bart-large-cnn, bart-large-xsum). Assuming 'facebook/bart-large-cnn' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2023-11-16 12:01:57 | INFO | transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/vocab.json from cache at /Users/rafiqmazen/.cache/torch/transformers/f81f1836206c8a8c5aff2ede75e57b33bdc48f82aef50597408258a95c5314f2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "2023-11-16 12:01:57 | INFO | transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/merges.txt from cache at /Users/rafiqmazen/.cache/torch/transformers/47dafd74e64f4d50d33ef3c4740a3a30073f5b38d25e83d5b33372e780e0de6f.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "2023-11-16 12:01:57 | INFO | transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/added_tokens.json from cache at None\n",
      "2023-11-16 12:01:57 | INFO | transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/special_tokens_map.json from cache at None\n",
      "2023-11-16 12:01:57 | INFO | transformers.tokenization_utils | loading file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/tokenizer_config.json from cache at None\n",
      "2023-11-16 12:01:58 | INFO | transformers.configuration_utils | loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/config.json from cache at /Users/rafiqmazen/.cache/torch/transformers/5f0de1d2bbb8eb1a3b69656622293b3328b06b701663a9d4109359751cb4e739.34ba3f954356a2e95322ec0779c171c5321b7ee576d59f741bfb8a4ebe69e978\n",
      "2023-11-16 12:01:58 | INFO | transformers.configuration_utils | Model config BartConfig {\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": null,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_sample\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "2023-11-16 12:01:58 | INFO | transformers.modeling_utils | loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/pytorch_model.bin from cache at /Users/rafiqmazen/.cache/torch/transformers/821c6fa2ec26e17b4ddc9f019177b20aedee71faf1797c1c109c1e651cc93819.73d71f0899e4bd27603a3503868c9f8cf938416df2de374c864a8c3af18f981d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input AMR: the girl like to travel\n",
      "Generated text: CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots of the U.S. for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots. For more travel news, visit CNN.org/Travel.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load pre-trained BART model and tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Example AMR input\n",
    "amr_input = \"the girl like to travel\"\n",
    "\n",
    "# Tokenize and encode the input AMR\n",
    "input_ids = tokenizer.encode(amr_input, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the output sequence\n",
    "output_ids = model.generate(input_ids)\n",
    "\n",
    "# Decode the generated output sequence\n",
    "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Input AMR:\", amr_input)\n",
    "print(\"Generated text:\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafiqmazen/anaconda3/envs/spring2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.64k/1.64k [00:00<00:00, 467kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.64G/1.64G [01:02<00:00, 26.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"xfbai/AMRBART-large-finetuned-AMR3.0-AMRParsing-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('spring2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09396d77aa5f751c350c1f23804f710a910791bd0f372ce87b698768334be15e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
